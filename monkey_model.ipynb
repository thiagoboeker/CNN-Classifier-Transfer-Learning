{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having some fun with CNNs!\n",
    "This is going to be a very standard project but I'm in a saturday night sitting at home, so I wanna have some fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\AppData\\Local\\Continuum\\anaconda3\\envs\\dlnd\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.applications import Xception\n",
    "from random import shuffle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Dataset\n",
    "Since the Dataset is so well strutucted, we will take advantage of that and write the function to get the data in a more hard way, but the clearest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(path, newWidth, newHeight):\n",
    "    \n",
    "    img = Image.open(path)\n",
    "    img = img.resize((newWidth, newHeight), Image.BILINEAR)\n",
    "    \n",
    "    return np.array(img.convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(directoryPath, width, height):\n",
    "    #Setting the paths\n",
    "    trainingArray = []\n",
    "    \n",
    "    validationArray = []\n",
    "    \n",
    "    \n",
    "    training_list_dirs = os.path.join(directoryPath, 'training/')\n",
    "    validation_list_dirs = os.path.join(directoryPath, 'validation/')\n",
    "    \n",
    "    n_classes = 10\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        dir_composit = ('n', str(i),'/')\n",
    "        training_files_dir = os.path.join(training_list_dirs, \"\".join(dir_composit))\n",
    "        training_files = os.listdir(training_files_dir)\n",
    "        \n",
    "        validation_files_dir = os.path.join(validation_list_dirs, \"\".join(dir_composit))\n",
    "        validation_files = os.listdir(validation_files_dir)\n",
    "        \n",
    "        for file in training_files:\n",
    "            trainingArray.append([getImage(os.path.join(training_files_dir,file), width, height), i])\n",
    "        for file in validation_files:\n",
    "            validationArray.append([getImage(os.path.join(validation_files_dir,file), width, height), i])\n",
    "        \n",
    "        shuffle(trainingArray)\n",
    "        shuffle(validationArray)\n",
    "        \n",
    "        training_set = [value[0] for value in trainingArray]\n",
    "        training_labels = [value[1] for value in trainingArray]\n",
    "        \n",
    "        validation_set = [value[0] for value in validationArray]\n",
    "        validation_labels = [value[1] for value in validationArray]\n",
    "        \n",
    "        val_size = int(len(validation_set)*0.5)\n",
    "        \n",
    "        test_set, test_labels = validation_set[val_size:], validation_labels[val_size:]\n",
    "        val_set, val_labels = validation_set[:val_size], validation_labels[:val_size]\n",
    "        \n",
    "            \n",
    "        \n",
    "    return np.array(training_set), np.array(test_set), np.array(training_labels), np.array(test_labels), np.array(val_set), np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, train_labels, test_labels, val_set, val_labels = getDataset('./10-monkey-species/', 150, 150)\n",
    "print(train_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "Using the Xception model to extract the features of the images, i've tested the data on a custom CNN and didnt got good results, so this is the way to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(imageData, model, mode = 'Inference', path = None):\n",
    "    \n",
    "    proc = tf.contrib.keras.applications.xception.preprocess_input(imageData.astype(np.float32))\n",
    "    \n",
    "    if mode != 'Inference':\n",
    "        results = model.predict(proc)\n",
    "        full_path = os.path.join(path, 'preprocessed_input')\n",
    "        os.makedirs(path)\n",
    "        np.save(full_path, results)\n",
    "        return results, full_path\n",
    "    else:\n",
    "        results = model.predict(proc)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadXception():\n",
    "    W = Path('xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    model = Xception(include_top = False, weights = W, pooling = 'max')\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputs(batch, n_classes):\n",
    "    size = batch.shape[1]\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=(None, size))\n",
    "    y = tf.placeholder(tf.int32, shape=(None))\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    return x, y, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_layer(x, n_classes, keep_prob):\n",
    "    \n",
    "    layer1 = tf.layers.dense(x, 512, activation = tf.nn.relu)\n",
    "    drop1 = tf.nn.dropout(layer1, keep_prob)\n",
    "    logits = tf.layers.dense(drop1, n_classes)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(logits, labels):\n",
    "    cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = labels)\n",
    "    loss = tf.reduce_mean(cost)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimizer(loss, learning_rate):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(logits, labels):\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    acc = tf.reduce_mean(tf.cast(correct, \"float\"))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadXception()\n",
    "pp_train, train_path = preprocessData(train_set, model, mode = 'Train', path = './logs/train')\n",
    "pp_val, val_path = preprocessData(val_set, model, mode = 'Train', path = './logs/val')\n",
    "pp_test, test_path = preprocessData(test_set, model, mode = 'Train', path = './logs/test' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 31\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "n_classes = 10\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0      Loss:0.9760555028915405        Accuracy:0.8823529481887817\n",
      "Epoch:1      Loss:0.6074819564819336        Accuracy:0.9338235259056091\n",
      "Epoch:2      Loss:0.35906195640563965        Accuracy:0.9411764740943909\n",
      "Epoch:3      Loss:0.2673106789588928        Accuracy:0.9558823704719543\n",
      "Epoch:4      Loss:0.33719488978385925        Accuracy:0.9632353186607361\n",
      "Epoch:5      Loss:0.1620817929506302        Accuracy:0.9558823704719543\n",
      "Epoch:6      Loss:0.1514054238796234        Accuracy:0.9632353186607361\n",
      "Epoch:7      Loss:0.13157455623149872        Accuracy:0.9485294222831726\n",
      "Epoch:8      Loss:0.15650434792041779        Accuracy:0.9485294222831726\n",
      "Epoch:9      Loss:0.08994272351264954        Accuracy:0.9558823704719543\n",
      "Epoch:10      Loss:0.08792774379253387        Accuracy:0.9632353186607361\n",
      "Epoch:11      Loss:0.05933644250035286        Accuracy:0.9485294222831726\n",
      "Epoch:12      Loss:0.06460656225681305        Accuracy:0.9558823704719543\n",
      "Epoch:13      Loss:0.11702905595302582        Accuracy:0.9558823704719543\n",
      "Epoch:14      Loss:0.04437757655978203        Accuracy:0.9558823704719543\n",
      "Epoch:15      Loss:0.03188557177782059        Accuracy:0.9632353186607361\n",
      "Epoch:16      Loss:0.04504479095339775        Accuracy:0.9632353186607361\n",
      "Epoch:17      Loss:0.0175820030272007        Accuracy:0.9558823704719543\n",
      "Epoch:18      Loss:0.042527519166469574        Accuracy:0.9632353186607361\n",
      "Epoch:19      Loss:0.0372992604970932        Accuracy:0.9632353186607361\n",
      "Epoch:20      Loss:0.036437541246414185        Accuracy:0.9558823704719543\n",
      "Epoch:21      Loss:0.017237521708011627        Accuracy:0.9558823704719543\n",
      "Epoch:22      Loss:0.05206139013171196        Accuracy:0.9485294222831726\n",
      "Epoch:23      Loss:0.022283334285020828        Accuracy:0.970588207244873\n",
      "Epoch:24      Loss:0.021704459562897682        Accuracy:0.9632353186607361\n",
      "Epoch:25      Loss:0.013992820866405964        Accuracy:0.970588207244873\n",
      "Epoch:26      Loss:0.019311994314193726        Accuracy:0.9558823704719543\n",
      "Epoch:27      Loss:0.010133950039744377        Accuracy:0.970588207244873\n",
      "Epoch:28      Loss:0.018407311290502548        Accuracy:0.9411764740943909\n",
      "Epoch:29      Loss:0.026324225589632988        Accuracy:0.9485294222831726\n",
      "Epoch:30      Loss:0.009813372045755386        Accuracy:0.9558823704719543\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x, y, k_prob = getInputs(pp_train, n_classes)\n",
    "\n",
    "logits = full_layer(x, n_classes, k_prob)\n",
    "\n",
    "cost = Loss(logits, y)\n",
    "\n",
    "optimizer = Optimizer(cost, learning_rate)\n",
    "\n",
    "accuracy = Accuracy(logits, y)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init.run()\n",
    "    \n",
    "    n_batches = int(len(pp_train)/batch_size)\n",
    "    x_batches = np.array_split(pp_train, n_batches)\n",
    "    y_batches = np.array_split(train_labels, n_batches)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for batch in range(n_batches):\n",
    "            \n",
    "            x_batch, y_batch = x_batches[batch], y_batches[batch]\n",
    "            \n",
    "            feed = {x:x_batch, y: y_batch, k_prob: keep_prob}\n",
    "            \n",
    "            _, loss = sess.run([optimizer, cost], feed_dict = feed)\n",
    "        \n",
    "        \n",
    "        acc = accuracy.eval({x:pp_val, y:val_labels, k_prob: 1})\n",
    "        print(\"Epoch:{}      Loss:{}        Accuracy:{}\".format(epoch, loss, acc))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, './logs/model/monkeys_cnn.ckpt')\n",
    "    \n",
    "    print(\"Optimization Finished!\")\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/model/monkeys_cnn.ckpt\n",
      "0.9558824\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './logs/model/monkeys_cnn.ckpt')\n",
    "    acc = accuracy.eval({x:pp_test, y:test_labels, k_prob:1})\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This is it! Over 95% of accuracy in a relative small dataset, I could use some tricks to maybe get a better result like the Keras ImageGenerator but this was good overall. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
